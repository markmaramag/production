{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with parquet files\n",
    "\n",
    "## Objective\n",
    "\n",
    "+ In this assignment, we will use the data downloaded with the module `data_manager` to create features.\n",
    "\n",
    "(11 pts total)\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "+ This notebook assumes that price data is available to you in the environment variable `PRICE_DATA`. If you have not done so, then execute the notebook `01_materials/labs/2_data_engineering.ipynb` to create this data set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Load the environment variables using dotenv. (1 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "# Write your code below.\n",
    "%load_ext dotenv\n",
    "%dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Load the environment variable `PRICE_DATA`.\n",
    "+ Use [glob](https://docs.python.org/3/library/glob.html) to find the path of all parquet files in the directory `PRICE_DATA`.\n",
    "\n",
    "(1pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Write your code below.\n",
    "import sys\n",
    "sys.path.append(os.getenv('SRC_DIR'))\n",
    "\n",
    "# Load the PRICE_DATA environment variable\n",
    "PRICE_DATA = os.getenv(\"PRICE_DATA\")\n",
    "\n",
    "parquet_files = glob(os.path.join(PRICE_DATA, \"**/part.0.parquet\"), recursive=True)\n",
    "\n",
    "# Load the data\n",
    "dd_px = dd.read_parquet(parquet_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11207"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(parquet_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each ticker and using Dask, do the following:\n",
    "\n",
    "+ Add lags for variables Close and Adj_Close.\n",
    "+ Add returns based on Adjusted Close:\n",
    "    \n",
    "    - `returns`: (Adj Close / Adj Close_lag) - 1\n",
    "\n",
    "+ Add the following range: \n",
    "\n",
    "    - `hi_lo_range`: this is the day's High minus Low.\n",
    "\n",
    "+ Assign the result to `dd_feat`.\n",
    "\n",
    "(4 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marky\\AppData\\Local\\Temp\\ipykernel_16992\\492660799.py:1: UserWarning: `meta` is not specified, inferred from partial data. Please provide `meta` if the result is unexpected.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta={'x': 'f8', 'y': 'f8'}) for dataframe result\n",
      "  or:     .apply(func, meta=('x', 'f8'))            for series result\n",
      "  ddf = dd_px.groupby('ticker', group_keys=False).apply(\n"
     ]
    }
   ],
   "source": [
    "# Add lags for variables Close and Adj_Close\n",
    "ddf = dd_px.groupby('ticker', group_keys=False).apply(\n",
    "    lambda x: x.assign(\n",
    "        Close_lag=x['Close'].shift(1),\n",
    "        Adj_Close_lag=x['Adj Close'].shift(1)\n",
    "    )\n",
    " )\n",
    "\n",
    "# Add returns based on Adjusted Close\n",
    "ddf['returns'] = (ddf['Adj Close'] / ddf['Adj_Close_lag']) - 1\n",
    "\n",
    "# Add the following range\n",
    "ddf['hi_lo_range'] = ddf['High'] - ddf['Low']\n",
    "\n",
    "# Assign the result to `dd_feat`\n",
    "dd_feat = ddf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>sector</th>\n",
       "      <th>subsector</th>\n",
       "      <th>year</th>\n",
       "      <th>Close_lag</th>\n",
       "      <th>Adj_Close_lag</th>\n",
       "      <th>returns</th>\n",
       "      <th>hi_lo_range</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=11207</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>datetime64[ns, UTC]</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>int32</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: assign, 18 graph layers</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "                                  Date Adj Close    Close     High      Low     Open Volume  sector subsector   year Close_lag Adj_Close_lag  returns hi_lo_range\n",
       "npartitions=11207                                                                                                                                                \n",
       "                   datetime64[ns, UTC]   float64  float64  float64  float64  float64  int64  object    object  int32   float64       float64  float64     float64\n",
       "                                   ...       ...      ...      ...      ...      ...    ...     ...       ...    ...       ...           ...      ...         ...\n",
       "...                                ...       ...      ...      ...      ...      ...    ...     ...       ...    ...       ...           ...      ...         ...\n",
       "                                   ...       ...      ...      ...      ...      ...    ...     ...       ...    ...       ...           ...      ...         ...\n",
       "                                   ...       ...      ...      ...      ...      ...    ...     ...       ...    ...       ...           ...      ...         ...\n",
       "Dask Name: assign, 18 graph layers"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dask Index Structure:\n",
       "npartitions=11207\n",
       "    object\n",
       "       ...\n",
       "     ...  \n",
       "       ...\n",
       "       ...\n",
       "Name: ticker, dtype: object\n",
       "Dask Name: assign-index, 19 graph layers"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd_feat.index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Convert the Dask data frame to a pandas data frame. \n",
    "+ Add a rolling average return calculation with a window of 10 days.\n",
    "+ *Tip*: Consider using `.rolling(10).mean()`.\n",
    "\n",
    "(3 pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price ticker                      Date   Adj Close       Close        High  \\\n",
      "0        HUM 2023-01-03 00:00:00+00:00  492.875916  500.489990  511.010010   \n",
      "1        HUM 2023-01-04 00:00:00+00:00  484.633301  492.119995  501.519989   \n",
      "2        HUM 2023-01-05 00:00:00+00:00  480.595673  488.019989  493.369995   \n",
      "3        HUM 2023-01-06 00:00:00+00:00  485.046906  492.540009  494.660004   \n",
      "4        HUM 2023-01-09 00:00:00+00:00  474.381653  481.709991  499.839996   \n",
      "\n",
      "Price         Low        Open   Volume       sector            subsector  \\\n",
      "0      489.670013  508.239990  1089500  Health Care  Managed Health Care   \n",
      "1      484.750000  500.130005  1137100  Health Care  Managed Health Care   \n",
      "2      483.709991  492.200012  1273800  Health Care  Managed Health Care   \n",
      "3      488.029999  490.230011   977600  Health Care  Managed Health Care   \n",
      "4      479.809998  495.570007  1065400  Health Care  Managed Health Care   \n",
      "\n",
      "Price  year   Close_lag  Adj_Close_lag   returns  hi_lo_range  \\\n",
      "0      2023         NaN            NaN       NaN    21.339996   \n",
      "1      2023  500.489990     492.875916 -0.016724    16.769989   \n",
      "2      2023  492.119995     484.633301 -0.008331     9.660004   \n",
      "3      2023  488.019989     480.595673  0.009262     6.630005   \n",
      "4      2023  492.540009     485.046906 -0.021988    20.029999   \n",
      "\n",
      "Price  rolling_avg_return  \n",
      "0                     NaN  \n",
      "1                     NaN  \n",
      "2                     NaN  \n",
      "3                     NaN  \n",
      "4                     NaN  \n"
     ]
    }
   ],
   "source": [
    "# Convert the Dask DataFrame to a Pandas DataFrame\n",
    "df_pandas = dd_feat.compute()\n",
    "\n",
    "# Make sure ticker is a column, not an index\n",
    "if 'ticker' not in df_pandas.columns:\n",
    "    df_pandas = df_pandas.reset_index()  # This will bring all index levels into columns\n",
    "\n",
    "# Calculate 10-day rolling average return for each ticker\n",
    "df_pandas['rolling_avg_return'] = (df_pandas.groupby('ticker')['returns']\n",
    "                                           .rolling(10)\n",
    "                                           .mean()\n",
    "                                           .reset_index(level=0, drop=True))\n",
    "\n",
    "# Display first few rows to verify\n",
    "print(df_pandas.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Please comment:\n",
    "\n",
    "+ Was it necessary to convert to pandas to calculate the moving average return?\n",
    "+ Would it have been better to do it in Dask? Why?\n",
    "\n",
    "(1 pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It wasn’t necessary to switch to Pandas to calculate the moving average return because Dask can do this on its own. Dask is actually a better choice for large datasets because it’s built to handle big data efficiently by processing chunks of data separately, which avoids memory issues. Using Dask for these calculations keeps things simple, prevents crashes, and skips the extra step of converting to Pandas, which can slow things down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criteria\n",
    "\n",
    "The [rubric](./assignment_1_rubric_clean.xlsx) contains the criteria for grading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Information\n",
    "\n",
    "🚨 **Please review our [Assignment Submission Guide](https://github.com/UofT-DSI/onboarding/blob/main/onboarding_documents/submissions.md)** 🚨 for detailed instructions on how to format, branch, and submit your work. Following these guidelines is crucial for your submissions to be evaluated correctly.\n",
    "\n",
    "### Submission Parameters:\n",
    "* Submission Due Date: `HH:MM AM/PM - DD/MM/YYYY`\n",
    "* The branch name for your repo should be: `assignment-1`\n",
    "* What to submit for this assignment:\n",
    "    * This Jupyter Notebook (assignment_1.ipynb) should be populated and should be the only change in your pull request.\n",
    "* What the pull request link should look like for this assignment: `https://github.com/<your_github_username>/production/pull/<pr_id>`\n",
    "    * Open a private window in your browser. Copy and paste the link to your pull request into the address bar. Make sure you can see your pull request properly. This helps the technical facilitator and learning support staff review your submission easily.\n",
    "\n",
    "Checklist:\n",
    "- [ ] Created a branch with the correct naming convention.\n",
    "- [ ] Ensured that the repository is public.\n",
    "- [ ] Reviewed the PR description guidelines and adhered to them.\n",
    "- [ ] Verify that the link is accessible in a private browser window.\n",
    "\n",
    "If you encounter any difficulties or have questions, please don't hesitate to reach out to our team via our Slack at `#cohort-3-help`. Our Technical Facilitators and Learning Support staff are here to help you navigate any challenges."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsi_participant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
